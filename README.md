# AI Agent for DevOps

A Python-based intelligent DevOps assistant using LangChain.  
Automates and simplifies DevOps tasks via an interactive AI chat interface.

## ğŸš€ Features

### Core Modules

- **ğŸ³ Docker Operations**: Container management, image operations, log viewing
- **ğŸ“Š System Monitoring**: CPU, memory, disk, and network usage
- **ğŸ“ File Management**: File and directory operations, content search
- **ğŸ“‹ Log Analysis**: Intelligent log parsing, error detection, report generation
- **âš¡ Performance Analysis**: Python program profiling
- **ğŸ”§ Service Management**: Check and restart system services

### AI Capabilities

- Natural language interactive interface
- Context-aware conversations
- Automated operational suggestions
- Intelligent task understanding and execution

## ğŸ“‹ System Requirements

- Python 3.8â€“3.11 (recommended 3.10 for compatibility)
- Docker (optional, for container operations)
- Linux/macOS/Windows (WSL2 compatible)

**Recommended**: use a Python 3.10 virtual environment:

```bash
# Ubuntu/WSL: Install Python 3.10
sudo apt update
sudo apt install python3.10 python3.10-venv python3.10-dev

# Create virtual environment
python3.10 -m venv venv
source venv/bin/activate


## ğŸ› ï¸ Installation

### 1. Clone the project

```bash
git clone <repository-url>
cd AIOpsAgent
```

### 2. Create and activate virtual environment

```bash
python -m venv venv
source venv/bin/activate      # Linux/macOS/WSL
# OR
venv\Scripts\activate         # Windows

```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure environment

Copy the example configuration and set your OpenAI API key:

```bash
cp config/config.yaml. config/config.local.yaml
```
and make sure put your `config.local.yaml` in `.gitignore`

Edit config/config.yaml
```bash
openai:
  api_key: "your-openai-api-key-here"
  model: "gpt-3.5-turbo"
```


## ğŸš€ Quick Start

### Run the AI Agent

```bash
python main.py
```

### Commands

```bash
# Start interactive chat
python main.py chat

# Check system status
python main.py status

# List available tools
python main.py tools

```


## ğŸ“ Project Structure

```
AIOpsAgent/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ core.py
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ docker_ops.py
â”‚   â”‚   â”œâ”€â”€ system_monitor.py
â”‚   â”‚   â”œâ”€â”€ file_manager.py
â”‚   â”‚   â”œâ”€â”€ log_analyzer.py
â”‚   â”‚   â””â”€â”€ service_check.py
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ entry.py
â”‚   â”‚   â”œâ”€â”€ interactive.py
â”‚   â”‚   â””â”€â”€ commands/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ chat_cmd.py
â”‚   â”‚       â”œâ”€â”€ status_cmd.py
â”‚   â”‚       â””â”€â”€ tools_cmd.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â”œâ”€â”€ helpers.py
â”‚       â””â”€â”€ exceptions.py
â””â”€â”€ logs/

```

## ğŸ”§ Configuration

### config/config.yaml

```yaml
openai:
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-3.5-turbo"
  temperature: 0.7
  max_tokens: 2000

monitoring:
  cpu_threshold: 80.0
  memory_threshold: 85.0
  disk_threshold: 90.0
  check_interval: 30

docker:
  socket_path: "unix://var/run/docker.sock"
  timeout: 30

logging:
  level: "INFO"
  file: "logs/agent.log"
  max_size: "10MB"
  backup_count: 5
```


## ğŸ“ Changelog

v1.1.0 (2025-10-5)
- Refactored the project into a more modular and maintainable directory structure, separating agents, CLI, utilities, tools, and configuration.
- Improved the agent core architecture, isolating initialization logic, prompt templates, and execution flow for better extensibility.
- Updated and cleaned dependency definitions in requirements.txt, removing unused packages and aligning versions with the new LangChain / OpenAI SDK implementations.
- Enhanced internal error handling to provide clearer diagnostics during agent initialization and runtime.
- Introduced clearer boundaries between components such as LLM wrappers, tool definitions, and execution pipelines.

v1.0.0 (2025-9-5)
- Initial project setup.
- Implemented basic CLI.
- Added simple LLM wrapper and preliminary tool integration.



